{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Video Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Importation des librairies**"
      ],
      "metadata": {
        "id": "9h7lotBu_9fD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "aWA1g-dCHz6F"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "# import pafy\n",
        "# import math\n",
        "import random\n",
        "import numpy as np\n",
        "# import datetime as dt\n",
        "import tensorflow as tf\n",
        "# from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# from moviepy.editor import *\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "# from tensorflow.keras.utils import plot_model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed_constant = 11\n",
        "np.random.seed(seed_constant)\n",
        "random.seed(seed_constant)\n",
        "tf.random.set_seed(seed_constant)"
      ],
      "metadata": {
        "id": "smg3Z4ftKHeE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Importation des données**"
      ],
      "metadata": {
        "id": "3hjBrG8eA_47"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous allons utiliser le jeu de données suivant  [UCF50 - Action Recognition Dataset](https://www.crcv.ucf.edu/data/UCF50.php).  \n",
        "Ce dataset contient des vidéos réalistes extraites de Youtube."
      ],
      "metadata": {
        "id": "zhvyj_-1BIOd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate https://www.crcv.ucf.edu/data/UCF50.rar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXRdK4PrH6lh",
        "outputId": "66e5e05a-5bda-4a89-b490-deed6e3b0923"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-04 17:09:55--  https://www.crcv.ucf.edu/data/UCF50.rar\n",
            "Resolving www.crcv.ucf.edu (www.crcv.ucf.edu)... 132.170.214.127\n",
            "Connecting to www.crcv.ucf.edu (www.crcv.ucf.edu)|132.170.214.127|:443... connected.\n",
            "WARNING: cannot verify www.crcv.ucf.edu's certificate, issued by ‘CN=InCommon RSA Server CA,OU=InCommon,O=Internet2,L=Ann Arbor,ST=MI,C=US’:\n",
            "  Unable to locally verify the issuer's authority.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3233554570 (3.0G) [application/rar]\n",
            "Saving to: ‘UCF50.rar.1’\n",
            "\n",
            "UCF50.rar.1         100%[===================>]   3.01G  13.0MB/s    in 3m 58s  \n",
            "\n",
            "2022-06-04 17:13:56 (12.9 MB/s) - ‘UCF50.rar.1’ saved [3233554570/3233554570]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unrar x UCF50.rar data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fE_JbdHsI5kK",
        "outputId": "0aba1528-f0bc-42e4-d732-1acb065d4b0b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from UCF50.rar\n",
            "\n",
            "\n",
            "Would you like to replace the existing file data/UCF50/BaseballPitch/v_BaseballPitch_g01_c01.avi\n",
            "318098 bytes, modified on 2010-10-01 15:49\n",
            "with a new one\n",
            "318098 bytes, modified on 2010-10-01 15:49\n",
            "\n",
            "[Y]es, [N]o, [A]ll, n[E]ver, [R]ename, [Q]uit \n",
            "User break\n",
            "\n",
            "User break\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Prétraitement des données**"
      ],
      "metadata": {
        "id": "0Z5vihmvCY9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inititialisation des variables"
      ],
      "metadata": {
        "id": "veLumMEJCpkW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Définition de la hauteur et de la largeur auquelles chaque video frame du dataset sera redimensionné\n",
        "IMAGE_HEIGHT , IMAGE_WIDTH = 64, 64\n",
        "\n",
        "# Définition du nombre de frames qui seront transmises au modèle en une seule séquence pour chaque vidéo\n",
        "SEQUENCE_LENGTH = 20\n",
        "\n",
        "# Répertoire contenant le jeu de données\n",
        "DATASET_DIR = \"/content/data/UCF50\"\n",
        "\n",
        "# Liste des noms des classes utilisés lors de l'entrainement\n",
        "CLASSES_LIST = [\"Punch\", \"YoYo\", \"Swing\", \"HorseRace\"]"
      ],
      "metadata": {
        "id": "RfOgJEF2IBEK"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Création d'une fonction pour extraire, redimensionner et normaliser les frames"
      ],
      "metadata": {
        "id": "Eg_fIdwLEOW1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous allons créer une fonction qui permet d'extraire les frames d'une vidéo, après les avoir redimensionné et normalisé.  \n",
        "\n",
        "Elle prend en argument le chemin d'accès à la vidéo de laquelle nous souhaitons extraire les frames et retourne une liste contenant les frames redimensionnés et normalisés."
      ],
      "metadata": {
        "id": "dudDeYlsE8A_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def frames_extraction(video_path):\n",
        "\n",
        "    # Liste pour stocker les video frames\n",
        "    frames_list = []\n",
        "    \n",
        "    # Lecture du fichier vidéo en utilisant l'objet VideoCapture\n",
        "    video_reader = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Nombre total de frames dans la vidéo\n",
        "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Calcul de l'interval après lequel chaque frame sera ajouté à la liste\n",
        "    skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH), 1)\n",
        "\n",
        "    # Parcours des video frames\n",
        "    for frame_counter in range(SEQUENCE_LENGTH):\n",
        "\n",
        "        # Définition de la position actuelle du frame de la vidéo\n",
        "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
        "\n",
        "        # Lecture du frame à partir de la vidéo \n",
        "        success, frame = video_reader.read() \n",
        "\n",
        "        if not success:\n",
        "            break\n",
        "\n",
        "        # Redimensionnement du frame\n",
        "        resized_frame = cv2.resize(frame, (IMAGE_HEIGHT, IMAGE_WIDTH))\n",
        "        # Normalisation du frame redimensionné en le divisant par 255 pour que la valeur de chaque pixel soit comprise entre 0 et 1\n",
        "        normalized_frame = resized_frame / 255\n",
        "        \n",
        "        # Ajout du frame normalisé à la liste des frames\n",
        "        frames_list.append(normalized_frame)\n",
        "    \n",
        "    video_reader.release()\n",
        "\n",
        "    return frames_list"
      ],
      "metadata": {
        "id": "0DZKn2pYJY9g"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensuite, nous allons créer une fonction qui parcourra toutes les classes spécifiées dans la constante CLASSES_LIST et appellera la fonction frame_extraction() sur chaque fichier vidéo des classes sélectionnées et renverra les images (features), l'index de classe (labels) , et le chemin du fichier vidéo (video_files_paths)."
      ],
      "metadata": {
        "id": "Lyf-pR2-Q2_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset():\n",
        "\n",
        "    features = []\n",
        "    labels = []\n",
        "    video_files_paths = []\n",
        "    \n",
        "    for class_index, class_name in enumerate(CLASSES_LIST):   \n",
        "        print(f'Extraction des données de la Classe: {class_name}')\n",
        "        \n",
        "        # liste des fichiers vidéos présents dans le répertoire du class name\n",
        "        files_list = os.listdir(os.path.join(DATASET_DIR, class_name))\n",
        "        for file_name in files_list:\n",
        "            \n",
        "            video_file_path = os.path.join(DATASET_DIR, class_name, file_name)\n",
        "            # Extraction des frames du fichier vidéo\n",
        "            frames = frames_extraction(video_file_path)\n",
        "            # Prendre en compte uniquement les frames de longueur égale à SEQUENCE_LENGTH\n",
        "            if len(frames) == SEQUENCE_LENGTH:\n",
        "                features.append(frames)\n",
        "                labels.append(class_index)\n",
        "                video_files_paths.append(video_file_path)\n",
        "    #Conversion des listes en numpy arrays\n",
        "    features = np.asarray(features)\n",
        "    labels = np.array(labels)  \n",
        "    \n",
        "    return features, labels, video_files_paths"
      ],
      "metadata": {
        "id": "W6UJaox4Jbp7"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Création du dataset\n",
        "features, labels, video_files_paths = create_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7fVhaekJqn1",
        "outputId": "614c3293-1740-4d25-cda9-a4b23921f4d8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction des données de la Classe: Punch\n",
            "Extraction des données de la Classe: YoYo\n",
            "Extraction des données de la Classe: Swing\n",
            "Extraction des données de la Classe: HorseRace\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Conversion des labels en one-hot-encoded vectors\n",
        "one_hot_encoded_labels = to_categorical(labels)"
      ],
      "metadata": {
        "id": "BJQShgMYJttB"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Partitionnement des données en ensembles d'entrainement et de test**\n",
        "\n"
      ],
      "metadata": {
        "id": "x-OJNocWTtlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_train, features_test, labels_train, labels_test = train_test_split(features, one_hot_encoded_labels,\n",
        "                                                                            test_size = 0.25, shuffle = True,\n",
        "                                                                            random_state = 23)"
      ],
      "metadata": {
        "id": "ptZH9DGwKAX_"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Implémentation du modèle**"
      ],
      "metadata": {
        "id": "fD1ZG3EXUuNy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Construction du modèle"
      ],
      "metadata": {
        "id": "ZOHljHSTomXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "   \n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(ConvLSTM2D(filters = 4, kernel_size = (3, 3), activation = 'tanh',\n",
        "                         recurrent_dropout=0.2, return_sequences=True, input_shape = (SEQUENCE_LENGTH,\n",
        "                                                                                      IMAGE_HEIGHT, IMAGE_WIDTH, 3)))\n",
        "    \n",
        "    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same'))\n",
        "    model.add(TimeDistributed(Dropout(0.2)))\n",
        "    \n",
        "    model.add(ConvLSTM2D(filters = 8, kernel_size = (3, 3), activation = 'tanh',\n",
        "                         recurrent_dropout=0.2, return_sequences=True))\n",
        "    \n",
        "    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same'))\n",
        "    model.add(TimeDistributed(Dropout(0.2)))\n",
        "    \n",
        "    model.add(ConvLSTM2D(filters = 14, kernel_size = (3, 3), activation = 'tanh',\n",
        "                         recurrent_dropout=0.2, return_sequences=True))\n",
        "    \n",
        "    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same'))\n",
        "    model.add(TimeDistributed(Dropout(0.2)))\n",
        "\n",
        "    model.add(ConvLSTM2D(filters = 16, kernel_size = (3, 3), activation = 'tanh',\n",
        "                         recurrent_dropout=0.2, return_sequences=True))\n",
        "    \n",
        "    model.add(MaxPooling3D(pool_size=(1, 2, 2), padding='same'))\n",
        "    \n",
        "    model.add(Flatten()) \n",
        "    \n",
        "    model.add(Dense(len(CLASSES_LIST), activation = \"softmax\"))\n",
        "    \n",
        "    \n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "l66OFPuBErZZ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_model = create_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7e55yerOiD9",
        "outputId": "8a81aa8e-0508-4f1f-9141-d592ffe5f20a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv_lstm2d_4 (ConvLSTM2D)  (None, 20, 62, 62, 4)     1024      \n",
            "                                                                 \n",
            " max_pooling3d_4 (MaxPooling  (None, 20, 31, 31, 4)    0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " time_distributed_3 (TimeDis  (None, 20, 31, 31, 4)    0         \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " conv_lstm2d_5 (ConvLSTM2D)  (None, 20, 29, 29, 8)     3488      \n",
            "                                                                 \n",
            " max_pooling3d_5 (MaxPooling  (None, 20, 15, 15, 8)    0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " time_distributed_4 (TimeDis  (None, 20, 15, 15, 8)    0         \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " conv_lstm2d_6 (ConvLSTM2D)  (None, 20, 13, 13, 14)    11144     \n",
            "                                                                 \n",
            " max_pooling3d_6 (MaxPooling  (None, 20, 7, 7, 14)     0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " time_distributed_5 (TimeDis  (None, 20, 7, 7, 14)     0         \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " conv_lstm2d_7 (ConvLSTM2D)  (None, 20, 5, 5, 16)      17344     \n",
            "                                                                 \n",
            " max_pooling3d_7 (MaxPooling  (None, 20, 3, 3, 16)     0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 2880)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 11524     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 44,524\n",
            "Trainable params: 44,524\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compilation et entrainement du modèle"
      ],
      "metadata": {
        "id": "W3-7cBo6pa4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an Instance of Early Stopping Callback\n",
        "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 10, mode = 'min', restore_best_weights = True)\n",
        "\n",
        "# Compile the model and specify loss function, optimizer and metrics values to the model\n",
        "conv_model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
        "\n",
        "# Start training the model.\n",
        "convl_model_training_history = conv_model.fit(x = features_train, y = labels_train, epochs = 50, batch_size = 4,\n",
        "                                                     shuffle = True, validation_split = 0.2, \n",
        "                                                     callbacks = [early_stopping_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exz_3AzKOnlw",
        "outputId": "4813b478-8435-4ecb-8d4c-dded83c9b7a8"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "83/83 [==============================] - 54s 540ms/step - loss: 1.3826 - accuracy: 0.3112 - val_loss: 1.3602 - val_accuracy: 0.3494\n",
            "Epoch 2/50\n",
            "83/83 [==============================] - 43s 521ms/step - loss: 1.1665 - accuracy: 0.5227 - val_loss: 0.9256 - val_accuracy: 0.7711\n",
            "Epoch 3/50\n",
            "83/83 [==============================] - 43s 523ms/step - loss: 0.7289 - accuracy: 0.7009 - val_loss: 0.6701 - val_accuracy: 0.7711\n",
            "Epoch 4/50\n",
            "83/83 [==============================] - 43s 516ms/step - loss: 0.5245 - accuracy: 0.8036 - val_loss: 0.5000 - val_accuracy: 0.8072\n",
            "Epoch 5/50\n",
            "83/83 [==============================] - 43s 521ms/step - loss: 0.3905 - accuracy: 0.8701 - val_loss: 0.4540 - val_accuracy: 0.8072\n",
            "Epoch 6/50\n",
            "83/83 [==============================] - 44s 525ms/step - loss: 0.2793 - accuracy: 0.8973 - val_loss: 0.4750 - val_accuracy: 0.8434\n",
            "Epoch 7/50\n",
            "83/83 [==============================] - 43s 518ms/step - loss: 0.2636 - accuracy: 0.9003 - val_loss: 0.4330 - val_accuracy: 0.8675\n",
            "Epoch 8/50\n",
            "83/83 [==============================] - 43s 519ms/step - loss: 0.1642 - accuracy: 0.9426 - val_loss: 0.4513 - val_accuracy: 0.8434\n",
            "Epoch 9/50\n",
            "83/83 [==============================] - 43s 523ms/step - loss: 0.1256 - accuracy: 0.9577 - val_loss: 0.3969 - val_accuracy: 0.8554\n",
            "Epoch 10/50\n",
            "83/83 [==============================] - 45s 537ms/step - loss: 0.1980 - accuracy: 0.9335 - val_loss: 0.3366 - val_accuracy: 0.9036\n",
            "Epoch 11/50\n",
            "83/83 [==============================] - 45s 545ms/step - loss: 0.0950 - accuracy: 0.9668 - val_loss: 0.3722 - val_accuracy: 0.8795\n",
            "Epoch 12/50\n",
            "83/83 [==============================] - 44s 526ms/step - loss: 0.1368 - accuracy: 0.9547 - val_loss: 0.3141 - val_accuracy: 0.8916\n",
            "Epoch 13/50\n",
            "83/83 [==============================] - 43s 521ms/step - loss: 0.0394 - accuracy: 0.9909 - val_loss: 0.1849 - val_accuracy: 0.9277\n",
            "Epoch 14/50\n",
            "83/83 [==============================] - 44s 532ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 0.2128 - val_accuracy: 0.9157\n",
            "Epoch 15/50\n",
            "83/83 [==============================] - 43s 516ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 0.1808 - val_accuracy: 0.9518\n",
            "Epoch 16/50\n",
            "83/83 [==============================] - 43s 518ms/step - loss: 0.0131 - accuracy: 0.9909 - val_loss: 0.6497 - val_accuracy: 0.8193\n",
            "Epoch 17/50\n",
            "83/83 [==============================] - 43s 517ms/step - loss: 0.0294 - accuracy: 0.9970 - val_loss: 0.3643 - val_accuracy: 0.8916\n",
            "Epoch 18/50\n",
            "83/83 [==============================] - 44s 528ms/step - loss: 0.1282 - accuracy: 0.9517 - val_loss: 0.4942 - val_accuracy: 0.8313\n",
            "Epoch 19/50\n",
            "83/83 [==============================] - 43s 515ms/step - loss: 0.2987 - accuracy: 0.8973 - val_loss: 0.3868 - val_accuracy: 0.8193\n",
            "Epoch 20/50\n",
            "83/83 [==============================] - 43s 514ms/step - loss: 0.0481 - accuracy: 0.9909 - val_loss: 0.4091 - val_accuracy: 0.8313\n",
            "Epoch 21/50\n",
            "83/83 [==============================] - 43s 514ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.4124 - val_accuracy: 0.8675\n",
            "Epoch 22/50\n",
            "83/83 [==============================] - 43s 518ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.4315 - val_accuracy: 0.8554\n",
            "Epoch 23/50\n",
            "83/83 [==============================] - 44s 531ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.4008 - val_accuracy: 0.8675\n",
            "Epoch 24/50\n",
            "83/83 [==============================] - 43s 518ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.4118 - val_accuracy: 0.8675\n",
            "Epoch 25/50\n",
            "83/83 [==============================] - 43s 517ms/step - loss: 0.0078 - accuracy: 0.9970 - val_loss: 0.5377 - val_accuracy: 0.8434\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation du modèle"
      ],
      "metadata": {
        "id": "Mn6lOovjp_Dq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_evaluation_history = conv_model.evaluate(features_test, labels_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyQql01LOuK1",
        "outputId": "98674686-7203-4f0e-eca4-056c6fb47556"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 72ms/step - loss: 0.5544 - accuracy: 0.8986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Enregistrement du modèle"
      ],
      "metadata": {
        "id": "UhTcGs5sqB4T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n",
        "\n",
        "model_file_name = f\"model_Loss_{%.2f} % {model_evaluation_loss}_Accuracy_{%.2f} % {model_evaluation_accuracy}.h5\"\n",
        "\n",
        "conv_model.save(model_file_name)"
      ],
      "metadata": {
        "id": "ciQdgFTmT2xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "evQpvl14vyYg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}